<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Invariance Co-Training for Robot Visual Generalization">
  <meta name="keywords" content="Robot Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Invariance Co-Training for Robot Visual Generalization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    /* Global Styles */
    body {
      font-family: 'Google Sans', 'Noto Sans', Arial, sans-serif;
      line-height: 1.6;
      color: #333;
    }

    /* Enhanced Typography */
    .title {
      font-weight: 600;
      margin-bottom: 1.5rem;
    }

    .subtitle {
      font-weight: 400;
      line-height: 1.8;
      color: #555;
      margin-top: 1.5rem;
    }

    .publication-title {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }

    /* Enhanced Buttons */
    .button {
      border-radius: 12px;
      transition: all 0.3s ease;
      font-weight: 500;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    }

    .button:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(0, 0, 0, 0.15);
    }

    /* Section Styling */
    .section {
      padding: 3rem 1.5rem;
    }

    .hero.teaser {
      background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
      padding: 2rem 0;
    }

    /* Image Enhancements */
    .teaser-image {
      border-radius: 12px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease;
    }

    .teaser-image:hover {
      transform: scale(1.02);
    }

    /* Video Styling */
    video {
      border-radius: 12px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.15);
    }

    /* Modern Tab Design */
    .tab {
      display: flex;
      justify-content: center;
      margin: 2rem 0;
      background: #fff;
      border-radius: 16px;
      padding: 8px;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
      backdrop-filter: blur(10px);
    }

    .tab button {
      background: transparent;
      border: none;
      outline: none;
      cursor: pointer;
      padding: 16px 32px;
      font-size: 16px;
      font-weight: 500;
      color: #666;
      border-radius: 12px;
      transition: all 0.3s ease;
      position: relative;
      overflow: hidden;
    }

    .tab button::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      transition: left 0.3s ease;
      z-index: -1;
    }

    .tab button:hover {
      color: #333;
      transform: translateY(-2px);
    }

    .tab button.active {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    }

    .tab button.active::before {
      left: 0;
    }

    /* Tab Content */
    .tabcontent {
      display: none;
      padding: 2rem 0;
      margin-top: 1rem;
    }

    /* GIF Container Improvements */
    .gif-row {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 2rem;
      flex-wrap: wrap;
      padding: 2rem 0;
    }

    .gif-item {
      width: 300px;
      height: auto;
      border-radius: 16px;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease;
    }

    .gif-item:hover {
      transform: scale(1.05);
    }

    /* Video Layout Enhancements */
    .video {
      position: relative;
      padding-bottom: 35%;
      border-radius: 12px;
      overflow: hidden;
    }

    .video iframe {
      width: 100%;
      height: 100%;
    }

    .center {
      margin-left: auto;
      margin-right: auto;
      display: block;
    }

    /* Improved Grid Layout for Videos */
    .video-grid {
      display: flex;
      justify-content: space-around;
      align-items: center;
      flex-wrap: wrap;
      gap: 1rem;
      padding: 1rem 0;
    }

    .video-item {
      flex: 1;
      min-width: 280px;
      max-width: 320px;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .video-item img {
      width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease;
    }

    .video-item img:hover {
      transform: scale(1.05);
    }

    /* Remove card styling from text sections - keep content clean */

    /* Responsive Design */
    @media (max-width: 768px) {
      .tab {
        flex-direction: column;
        align-items: center;
      }
      
      .tab button {
        width: 100%;
        margin-bottom: 0.5rem;
      }
      
      .video-grid {
        flex-direction: column;
      }
      
      .video-item {
        max-width: 100%;
      }
      
      .section {
        padding: 2rem 1rem;
      }
    }

    /* Remove conflicting legacy styles */
    #vid-left, #vid-mid, #vid-right {
      all: unset;
    }
  </style>

</head>
<body>

<!--
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
-->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Invariance Co-Training for Robot Visual Generalization</h1>
          <div class="is-size-5 publication-authors">
	</div>


          <div class="column has-text-centered">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
	<!--
	<video id="moma-video"
                 controls
		 autoplay
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/teaser.mp4"
                    type="video/mp4">
          </video>
	-->
      <img src="./static/new_images/main_teaser_v2.png"
                 class="teaser-image"
                 alt="Invariance Co-Training"/>
      <h2 class="subtitle has-text-centered">
	<strong>We train a 2D vision encoder that generalizes to new camera viewpoints, lighting conditions, and background clutter</strong> that leverages diverse synthetic images, large-scale open-source datasets, and videos of static scenes.
	</h2>
    </div>
  </div>
</section>


<!--/
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Navigation Videos</h2>
        </div>
      </div>
    </div>
</section> 
-->
<section class="hero is-light is-small">
  <div class="hero-body">
     <video class="center" id="moma-video"
                 controls
		 autoplay
                 muted
                 preload
                 playsinline
                 width="70%">
            <source src="./static/videos/main_video.mp4"
                    type="video/mp4">
          </video>
  <!--  
  <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
	<div class="item item-cluttered_grasp_compressed">
          <video poster="" id="cluttered_grasp_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/cluttered_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shelf_manipulation_compressed">
          <video poster="" id="shelf_manipulation_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/shelf_manip_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-bridge_thirdperson_compressed">
          <video poster="" id="bridge_thirdperson_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/toy_kitchen_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-locobot5">
          <video poster="" id="locobot5" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/locobot_first_floor_edited.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-locobot4">
          <video poster="" id="locobot4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/locobot_outside.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-locobot3">
          <video poster="" id="locobot3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/jackal_kitchen_edited.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-locobot2">
          <video poster="" id="locobot2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/jackal_first_floor_third_edited.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-locobot1">
          <video poster="" id="locobot1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/go1_outdoor.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-jackal1">
          <video poster="" id="jackal1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/go1_second_floor_edited.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-jackal2">
          <video poster="" id="jackal2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/drone_traj.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    -->
  </div>
</section>

<!--
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
	<div class="item item-cluttered_grasp_compressed">
          <video poster="" id="cluttered_grasp_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/cluttered_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shelf_manipulation_compressed">
          <video poster="" id="shelf_manipulation_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/shelf_manip_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-bridge_thirdperson_compressed">
          <video poster="" id="bridge_thirdperson_compressed" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/toy_kitchen_compressed.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="text-align: left;">
          <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">
	  Despite recent advancements, many large-scale robotic policies still remain sensitive to key sources of observational variation—such as changes in camera perspective, lighting, and the presence of distractor objects. We posit that the limited generalizability of these models arises from the substantial diversity required to robustly cover these quasistatic axes, coupled with the current scarcity of large-scale robotic datasets that exhibit rich variation across them.
	  </p>
	  <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">
	In this work, we propose to systematically examine what robots need to generalize across these challenging axes by introducing two key auxiliary tasks—state similarity and invariance to observational perturbations—applied to both demonstration data and static visual data. We then show that via these auxiliary tasks, leveraging both more-expensive robotic demonstration data and less-expensive, visually rich synthetic images generated from non-physics-based simulation (e.g., Unreal Engine) can lead to substantial increases in generalization to unseen camera viewpoints, lighting configurations, and distractor conditions.
	</p>
	<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 12px; color: white; text-align: center; margin-top: 2rem;">
	  <p style="font-size: 1.2rem; font-weight: 600; margin: 0;">
       Our results demonstrate that co-training on this diverse data improves performance by <strong style="font-size: 1.4rem;">18%</strong> over existing generative augmentation methods.
	  </p>
	</div>
        </div>
      </div>
    </div>

</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
	<video id="moma-video"
                 controls
		 autoplay
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/method_compressed.mp4"
                    type="video/mp4">
          </video>
      <h2 class="subtitle has-text-centered">
	<strong>Our approach demonstrates robust generalization</strong> across diverse visual conditions by leveraging synthetic imagery, open-source datasets, and static scene videos for enhanced robot vision training.
	</h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
	<!-- Re-rendering. -->
        <h2 class="title is-3" style="color: #667eea; border-bottom: 3px solid #667eea; padding-bottom: 0.5rem; margin-bottom: 2rem;">Invariance Co-Training as Contrastive Learning</h2>
        <div class="content has-text-justified" style="text-align: left;">
          <p>
         We propose a contrastive co-training framework where the policy learns representations invariant to observational perturbations (e.g., viewpoint, lighting) while remaining sensitive to task-relevant state and goal changes. By distinguishing between semantically similar and dissimilar (state, goal) pairs across varying observational conditions, the model learns to align representations that matter for control. 
	 </p>
        </div>
           <img src="./static/images/contrastive.png"
                 class="teaser-image"
                 alt="Invariance Co-Training as Contrastive Learning"/> 
	</div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
	<!-- Re-rendering. -->
        <h2 class="title is-3" style="color: #667eea; border-bottom: 3px solid #667eea; padding-bottom: 0.5rem; margin-bottom: 2rem;">Example Static Simulation Images</h2>
        <div class="content has-text-justified" style="text-align: left;">
          <p>
	The image depicts example simulation images from the simpler env, unreal engine, and libero simulators. 
	</p>
        </div>
           <img src="./static/images/sim_examples.png"
                 class="teaser-image"
		style="width: 50%; display: block; margin: 0 auto;"
		 alt="Invariance Co-Training as Contrastive Learning"/> 
	</div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="color: #667eea; border-bottom: 3px solid #667eea; padding-bottom: 0.5rem; margin-bottom: 2rem;">Generalization to Novel Observation Variations</h2>
        </div>
      </div>
        <div class="content has-text-justified" style="text-align: left;">
          <p>
        Experimentally, our invariance co-training approach significantly outperforms baseline Behavioral Cloning, improving average success rates by approximately 40% across key variations. Furthermore, it yields 18\% higher success rates compared to variants relying only on simulation or generative models.  
	</p>
        </div>
        
        <!-- Main Results Figure -->
        <div class="columns is-centered" style="margin-top: 3rem;">
          <div class="column is-full-width">
            <div class="content has-text-centered">
              <img src="./static/new_images/main_results.png"
                   class="teaser-image"
                   alt="Main Results - Performance comparison across different methods and variations"
                   style="width: 90%; max-width: 1000px;"/>
              <p style="margin-top: 1rem; color: #666; font-style: italic;">
                <strong>Quantitative Results:</strong> Our Invariance Co-Training approach consistently outperforms baseline methods across camera viewpoint changes, lighting variations, and background clutter scenarios.
              </p>
            </div>
          </div>
        </div>
    </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
<div class="tab">
  <button class="tablinks" onclick="openTab(event, 'Behavior Cloning')" id="defaultOpen">Behavior Cloning</button>
  <button class="tablinks" onclick="openTab(event, 'Invariance Co-Training')">Invariance Co-Training</button>
</div>

<div id="Behavior Cloning" class="tabcontent">
  <div class="video-grid">
    <div class="video-item">
      <img src="./static/videos/Variations/aux-fail.gif" alt="Auxiliary viewpoint failure case" />
    </div>
    <div class="video-item">
      <img src="./static/videos/Variations/clutter_fail.gif" alt="Background clutter failure case" />
    </div>
    <div class="video-item">
      <img src="./static/videos/Variations/lighting_fail.gif" alt="Lighting variation failure case" />
    </div>
  </div>
  <div class="content has-text-centered" style="margin-top: 1rem; color: #666;">
    <p><em>Baseline Behavior Cloning struggles with viewpoint changes, background clutter, and lighting variations</em></p>
  </div>
</div>
<div id="Invariance Co-Training" class="tabcontent">
  <div class="video-grid">
    <div class="video-item">
      <img src="./static/videos/Variations/aux-success.gif" alt="Auxiliary viewpoint success case" />
    </div>
    <div class="video-item">
      <img src="./static/videos/Variations/clutter_success.gif" alt="Background clutter success case" />
    </div>
    <div class="video-item">
      <img src="./static/videos/Variations/lighting_success.gif" alt="Lighting variation success case" />
    </div>
  </div>
  <div class="content has-text-centered" style="margin-top: 1rem; color: #666;">
    <p><em>Our Invariance Co-Training approach successfully handles the same challenging variations</em></p>
  </div>
</div>


<script>
function openTab(evt, cityName) {
  var i, tabcontent, tablinks;
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }
  document.getElementById(cityName).style.display = "block";
  evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>
</div>
</section>
   


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
	<!-- Re-rendering. -->
        <h2 class="title is-3" style="color: #667eea; border-bottom: 3px solid #667eea; padding-bottom: 0.5rem; margin-bottom: 2rem;">Handheld Camera Generalization</h2>
        <div class="content has-text-justified" style="text-align: left;">
          <p>
          Our method can generalize to new camera perspectives zero-shot in the DROID platform. 
	 </p>
        </div>
	<div class="content has-text-centered">
          <video id="moma-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="80%">
            <source src="./static/videos/handheld.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->
	</div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<!--
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>
-->


</body>
</html>
